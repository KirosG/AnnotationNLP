{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /anaconda3/envs/Annotation/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /anaconda3/envs/Annotation/lib/python3.6/site-packages (from sklearn) (0.19.1)\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-fft 1.0.0 requires cython, which is not installed.\u001b[0m\n",
      "Requirement already satisfied: scipy in /anaconda3/envs/Annotation/lib/python3.6/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /anaconda3/envs/Annotation/lib/python3.6/site-packages (from scipy) (1.14.5)\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-fft 1.0.0 requires cython, which is not installed.\u001b[0m\n",
      "Requirement already satisfied: pyConTextNLP in /anaconda3/envs/Annotation/lib/python3.6/site-packages (0.6.2.0)\n",
      "Requirement already satisfied: networkx==1.11 in /anaconda3/envs/Annotation/lib/python3.6/site-packages (from pyConTextNLP) (1.11)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /anaconda3/envs/Annotation/lib/python3.6/site-packages (from networkx==1.11->pyConTextNLP) (4.3.0)\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-fft 1.0.0 requires cython, which is not installed.\u001b[0m\n",
      "Requirement already satisfied: textblob in /anaconda3/envs/Annotation/lib/python3.6/site-packages (0.15.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /anaconda3/envs/Annotation/lib/python3.6/site-packages (from textblob) (3.3)\n",
      "Requirement already satisfied: six in /anaconda3/envs/Annotation/lib/python3.6/site-packages (from nltk>=3.1->textblob) (1.11.0)\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-fft 1.0.0 requires cython, which is not installed.\u001b[0m\n",
      "Collecting radnlp\n",
      "  Downloading https://files.pythonhosted.org/packages/89/e2/26f0d1029cc123ff999a45e6f1394d3621e15d9e7df89b7a932c80923ea2/radnlp-0.2.0.8-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyConTextNLP in /anaconda3/envs/Annotation/lib/python3.6/site-packages (from radnlp) (0.6.2.0)\n",
      "Requirement already satisfied: networkx==1.11 in /anaconda3/envs/Annotation/lib/python3.6/site-packages (from pyConTextNLP->radnlp) (1.11)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /anaconda3/envs/Annotation/lib/python3.6/site-packages (from networkx==1.11->pyConTextNLP->radnlp) (4.3.0)\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-fft 1.0.0 requires cython, which is not installed.\u001b[0m\n",
      "Installing collected packages: radnlp\n",
      "Successfully installed radnlp-0.2.0.8\n",
      "Loaded utilities...\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install scipy\n",
    "!pip install pyConTextNLP\n",
    "!pip install textblob\n",
    "!pip install radnlp\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "import codecs\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import sklearn.metrics\n",
    "\n",
    "# packages for interaction\n",
    "from IPython.html.widgets import interact, interactive, fixed\n",
    "from IPython.display import display, HTML, Image\n",
    "import ipywidgets\n",
    "\n",
    "# and also our utilities for this class\n",
    "from nlp_pneumonia_utils import Annotation\n",
    "from nlp_pneumonia_utils import AnnotatedDocument\n",
    "from nlp_pneumonia_utils import read_brat_annotations\n",
    "from nlp_pneumonia_utils import read_doc_annotations\n",
    "from nlp_pneumonia_utils import read_annotations\n",
    "from nlp_pneumonia_utils import calculate_prediction_metrics\n",
    "from nlp_pneumonia_utils import mark_text_custom\n",
    "from nlp_pneumonia_utils import clearPyConTextRegularExpressions\n",
    "from nlp_pneumonia_utils import pneumonia_annotation_html_markup\n",
    "print('Loaded utilities...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we'll load in our dataset but throughout these notebooks, there are a lot of utility functions used.  Feel free to look at them here : nlp_pneumonia_utils.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading annotations from file : data/training_v2.zip\n",
      "Opening local file : data/training_v2.zip\n",
      "Total Annotated Documents : 70\n",
      "Total Positive Pneumonia Documents : 34\n"
     ]
    }
   ],
   "source": [
    "# First thing, let's load our training set\n",
    "annotated_doc_map = read_doc_annotations('data/training_v2.zip')\n",
    "annotated_docs = list(annotated_doc_map.values())\n",
    "print('Total Annotated Documents : {0}'.format(len(annotated_docs)))\n",
    "\n",
    "total_positives = 0\n",
    "for anno_doc in annotated_docs:\n",
    "    if anno_doc.positive_label:\n",
    "        total_positives += 1\n",
    "    \n",
    "print('Total Positive Pneumonia Documents : {0}'.format(total_positives))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, let's look at some of the annotations annotated by our expert.  Note that there are 3 total annotation types in this set : \n",
    "1. **DOCUMENT_PNEUMONIA_YES* -> Document shows **active** or **possible** case of pneumonia\n",
    "2. **DOCUMENT_PNEUMONIA_NO** -> Document shows **no evidence** of pneumonia\n",
    "3. **SPAN_POSITIVE_PNEUMONIA_EVIDENCE** -> Spans of phrases/sentence which show positive or possible evidence of pneumonia which led the expert annotator to the final document-level conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's render one of our annotated documents in HTML.  When using the function 'pneumonia_annotation_html_markup' these show up as the colors:\n",
    "1. **DOCUMENT_PNEUMONIA_YES** -> RED\n",
    "2. **DOCUMENT_PNEUMONIA_NO** -> GREEN\n",
    "3. **SPAN_POSITIVE_PNEUMONIA_EVIDENCE** -> RED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also use widgets to \"scrub\" through the documents and examine any of the  expert annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This function let's us iterate through all documents and view the markup\n",
    "# Let's look at the first 4\n",
    "def view_annotation_markup(anno_docs):\n",
    "    @interact(i=ipywidgets.IntSlider(min=0, max=4)) #max=len(anno_docs)-1))\n",
    "    def _view_markup(i):\n",
    "        report_html = pneumonia_annotation_html_markup(anno_docs[i])\n",
    "        report_html = report_html.replace('\\n', '<br>')\n",
    "        display(HTML(report_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d7d015afa44cdb921628a93836261f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=4), Output()), _dom_classes=('widget-interact',)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_annotation_markup(annotated_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "<br/><br/>This material presented as part of the DeCART Data Science for the Health Science Summer Program at the University of Utah in 2017.<br/>\n",
    "Presenters : Dr. Wendy Chapman, Jianlin Shi and Kelly Peterson"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
